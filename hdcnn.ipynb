{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchically Deep Convolutional Neural Network For Image Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras as kr\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.datasets import cifar100\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from random import randint\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Global Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The number of coarse categories\n",
    "coarse_categories = 20\n",
    "\n",
    "# The number of fine categories\n",
    "fine_categories = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Preprocess Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Cifar100 Data Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X, y_c), (x_test, y_c_test) = cifar100.load_data(label_mode='coarse')\n",
    "(X, y), (x_test, y_test) = cifar100.load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fine-To-Coarse Mapping**\n",
    "\n",
    "(Ideally, this would be done through spectral clustering as opposed to hard-coding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fine2coarse = np.zeros((fine_categories,coarse_categories))\n",
    "for i in range(coarse_categories):\n",
    "    index = np.where(y_c_test[:,0] == i)[0]\n",
    "    fine_cat = np.unique([y_test[j,0] for j in index])\n",
    "    for j in fine_cat:\n",
    "        fine2coarse[j,i] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_c = 0; # Clear y_c in interest of saving mem\n",
    "y_c_test=0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#    Title: One Hot Encoding\n",
    "################################################################################\n",
    "#    Description: \n",
    "#        This function extends a matrix to one-hot encoding\n",
    "#    \n",
    "#    Parameters:\n",
    "#        y    Array of label values\n",
    "# \n",
    "#    Returns:\n",
    "#        y_new    One hot encoded array of labels\n",
    "################################################################################\n",
    "def one_hot(y):\n",
    "    n_values = np.max(y) + 1\n",
    "    y_new = np.eye(n_values)[y[:,0]]\n",
    "    return y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 100)\n"
     ]
    }
   ],
   "source": [
    "y=one_hot(y)\n",
    "y_test=one_hot(y_test)\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply ZCA Whitening**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#    Title: ZCA\n",
    "################################################################################\n",
    "#    Description: \n",
    "#        This function applies ZCA Whitening to the image set\n",
    "#    \n",
    "#    Parameters:\n",
    "#        x_1           Array of MxNxC images to compute the ZCA Whitening\n",
    "#        x_2           Array of MxNxC images to apply the ZCA transform\n",
    "#        num_batch    Number of batches to do the computation\n",
    "# \n",
    "#    Returns:\n",
    "#        An array of MxNxC zca whitened images\n",
    "################################################################################\n",
    "def zca(x_1, x_2, epsilon=1e-5):\n",
    "        \n",
    "    with tf.name_scope('ZCA'):\n",
    "        \n",
    "        x1 = tf.placeholder(tf.float64, shape=np.shape(x_1), name='placeholder_x1')\n",
    "        x2 = tf.placeholder(tf.float64, shape=np.shape(x_2), name='placeholder_x2')\n",
    "        \n",
    "        flatx = tf.cast(tf.reshape(x1, (-1, np.prod(x_1.shape[-3:])),name=\"reshape_flat\"),tf.float64,name=\"flatx\")\n",
    "        sigma = tf.tensordot(tf.transpose(flatx),flatx, 1,name=\"sigma\") / tf.cast(tf.shape(flatx)[0],tf.float64) ### N-1 or N?\n",
    "        s, u, v = tf.svd(sigma,name=\"svd\")\n",
    "        pc = tf.tensordot(tf.tensordot(u,tf.diag(1. / tf.sqrt(s+epsilon)),1,name=\"inner_dot\"),tf.transpose(u),1, name=\"pc\")\n",
    "        \n",
    "        net1 = tf.tensordot(flatx, pc,1,name=\"whiten1\")\n",
    "        net1 = tf.reshape(net1,np.shape(x_1), name=\"output1\")\n",
    "        \n",
    "        flatx2 = tf.cast(tf.reshape(x2, (-1, np.prod(x_2.shape[-3:])),name=\"reshape_flat2\"),tf.float64,name=\"flatx2\")\n",
    "        net2 = tf.tensordot(flatx2, pc,1,name=\"whiten2\")\n",
    "        net2 = tf.reshape(net2,np.shape(x_2), name=\"output2\")\n",
    "        \n",
    "    with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            x_1,x_2 = sess.run([net1,net2], feed_dict={x1: x_1, x2: x_2})    \n",
    "    return x_1,x_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed - ZCA Whitening: 47.44490122795105\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "X,x_test = zca(X,x_test)\n",
    "time2 = time.time()\n",
    "print('Time Elapsed - ZCA Whitening: '+str(time2-time1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Training set into Training and Validation sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=.1, random_state=0)\n",
    "X = 0\n",
    "y = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flip, pad and randomly crop each photo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#    Title: Preprocess Img\n",
    "################################################################################\n",
    "#    Description: \n",
    "#        This function pads images by 4 pixels, randomly crops them, then\n",
    "#        randomly flips them\n",
    "#    \n",
    "#    Parameters:\n",
    "#        x_1           Array of MxNxC images to compute the ZCA Whitening\n",
    "#        x_2           Array of MxNxC images to apply the ZCA transform\n",
    "#        num_batch    Number of batches to do the computation\n",
    "# \n",
    "#    Returns:\n",
    "#        An array of MxNxC zca whitened images\n",
    "################################################################################\n",
    "def preprocess_img(X,y):\n",
    "        \n",
    "    with tf.name_scope('Preproc'):\n",
    "        \n",
    "        images = tf.placeholder(tf.float64, shape=np.shape(X))\n",
    "        labels = tf.placeholder(tf.float64, shape=np.shape(y))\n",
    "        \n",
    "        net = tf.map_fn(lambda img: tf.image.flip_left_right(img), images)\n",
    "        net = tf.map_fn(lambda img: tf.image.rot90(img), net)\n",
    "        net = tf.image.resize_image_with_crop_or_pad(net,40,40)\n",
    "        net = tf.map_fn(lambda img: tf.random_crop(img, [32,32,3]), net)\n",
    "\n",
    "        net1 = tf.image.resize_image_with_crop_or_pad(images,40,40)\n",
    "        net1 = tf.map_fn(lambda img: tf.random_crop(img, [32,32,3]), net1)\n",
    "        \n",
    "        net = tf.concat([net, net1],0)\n",
    "        net = tf.random_shuffle(net, seed=0)\n",
    "        net_labels = tf.concat([labels, labels],0)\n",
    "        net_labels = tf.random_shuffle(net_labels,seed=0)\n",
    "        \n",
    "        net = tf.map_fn(lambda img: tf.image.random_flip_up_down(img), net)\n",
    "        \n",
    "    with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            x_t,y_t = sess.run([net,net_labels], feed_dict={images: X, labels: y})    \n",
    "    return x_t,y_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed - Img Preprocessing: 66.82172513008118\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "x_train,y_train = preprocess_img(x_train,y_train)\n",
    "time2 = time.time()\n",
    "print('Time Elapsed - Img Preprocessing: '+str(time2-time1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Classifier Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constructing CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.layers import Input, Conv2D, Dropout, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "in_layer = Input(shape=(32, 32, 3), dtype='float32', name='main_input')\n",
    "\n",
    "net = Conv2D(384, 3, strides=1, padding='same', activation='elu')(in_layer)\n",
    "net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "net = Conv2D(384, 1, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(384, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(640, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(640, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Dropout(.2)(net)\n",
    "net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "net = Conv2D(640, 1, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(768, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(768, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(768, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Dropout(.3)(net)\n",
    "net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "net = Conv2D(768, 1, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(896, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(896, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Dropout(.4)(net)\n",
    "net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "net = Conv2D(896, 3, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(1024, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(1024, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Dropout(.5)(net)\n",
    "net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "net = Conv2D(1024, 1, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(1152, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Dropout(.6)(net)\n",
    "net = MaxPooling2D((2, 2), padding='same')(net)\n",
    "\n",
    "net = Flatten()(net)\n",
    "net = Dense(1152, activation='elu')(net)\n",
    "net = Dense(100, activation='softmax')(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=in_layer,outputs=net)\n",
    "sgd_coarse = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer= sgd_coarse, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.load_weights('data/models/model_coarse'+str(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbCallBack = kr.callbacks.TensorBoard(log_dir='./data/graph/elu_drop/', histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "90000/90000 [==============================] - 702s - loss: 4.1678 - acc: 0.0558 - val_loss: 3.9135 - val_acc: 0.1132\n",
      "Epoch 2/5\n",
      "90000/90000 [==============================] - 699s - loss: 3.3947 - acc: 0.1657 - val_loss: 3.8714 - val_acc: 0.2070\n",
      "Epoch 3/5\n",
      "90000/90000 [==============================] - 699s - loss: 3.0618 - acc: 0.2287 - val_loss: 4.5739 - val_acc: 0.2350\n",
      "Epoch 4/5\n",
      "90000/90000 [==============================] - 699s - loss: 2.8058 - acc: 0.2842 - val_loss: 5.4959 - val_acc: 0.2396\n",
      "Epoch 5/5\n",
      "90000/90000 [==============================] - 699s - loss: 2.6057 - acc: 0.3282 - val_loss: 5.3397 - val_acc: 0.2920\n",
      "Train on 90000 samples, validate on 5000 samples\n",
      "Epoch 6/10\n",
      "90000/90000 [==============================] - 700s - loss: 2.4349 - acc: 0.3679 - val_loss: 5.5889 - val_acc: 0.3210\n",
      "Epoch 7/10\n",
      "90000/90000 [==============================] - 700s - loss: 2.2847 - acc: 0.4041 - val_loss: 4.1056 - val_acc: 0.3252\n",
      "Epoch 8/10\n",
      "90000/90000 [==============================] - 700s - loss: 2.1724 - acc: 0.4310 - val_loss: 4.1841 - val_acc: 0.3090\n",
      "Epoch 9/10\n",
      "90000/90000 [==============================] - 701s - loss: 2.0528 - acc: 0.4609 - val_loss: 5.2127 - val_acc: 0.3810\n",
      "Epoch 10/10\n",
      "90000/90000 [==============================] - 701s - loss: 1.9462 - acc: 0.4859 - val_loss: 4.6939 - val_acc: 0.3438\n",
      "Train on 90000 samples, validate on 5000 samples\n",
      "Epoch 11/15\n",
      "90000/90000 [==============================] - 701s - loss: 1.8747 - acc: 0.5054 - val_loss: 5.0871 - val_acc: 0.3694\n",
      "Epoch 12/15\n",
      "90000/90000 [==============================] - 700s - loss: 1.8041 - acc: 0.5243 - val_loss: 5.1457 - val_acc: 0.3666\n",
      "Epoch 13/15\n",
      "90000/90000 [==============================] - 700s - loss: 1.7303 - acc: 0.5433 - val_loss: 5.0779 - val_acc: 0.3990\n",
      "Epoch 14/15\n",
      "90000/90000 [==============================] - 700s - loss: 1.6837 - acc: 0.5572 - val_loss: 4.9813 - val_acc: 0.3882\n",
      "Epoch 15/15\n",
      "90000/90000 [==============================] - 701s - loss: 1.6414 - acc: 0.5680 - val_loss: 5.6310 - val_acc: 0.4072\n",
      "Train on 90000 samples, validate on 5000 samples\n",
      "Epoch 16/20\n",
      "90000/90000 [==============================] - 699s - loss: 1.6166 - acc: 0.5794 - val_loss: 5.9356 - val_acc: 0.3792\n",
      "Epoch 17/20\n",
      "90000/90000 [==============================] - 699s - loss: 1.5778 - acc: 0.5918 - val_loss: 6.3573 - val_acc: 0.4206\n",
      "Epoch 18/20\n",
      "90000/90000 [==============================] - 700s - loss: 1.5725 - acc: 0.5936 - val_loss: 5.9553 - val_acc: 0.4098\n",
      "Epoch 19/20\n",
      "90000/90000 [==============================] - 700s - loss: 1.5500 - acc: 0.6006 - val_loss: 6.4280 - val_acc: 0.3964\n",
      "Epoch 20/20\n",
      "90000/90000 [==============================] - 699s - loss: 1.5446 - acc: 0.6048 - val_loss: 6.1994 - val_acc: 0.4142\n",
      "Train on 90000 samples, validate on 5000 samples\n",
      "Epoch 21/25\n",
      "90000/90000 [==============================] - 699s - loss: 1.5475 - acc: 0.6078 - val_loss: 5.5940 - val_acc: 0.4162\n",
      "Epoch 22/25\n",
      "90000/90000 [==============================] - 699s - loss: 1.5658 - acc: 0.6041 - val_loss: 5.5062 - val_acc: 0.4212\n",
      "Epoch 23/25\n",
      "90000/90000 [==============================] - 698s - loss: 1.5875 - acc: 0.6026 - val_loss: 5.3446 - val_acc: 0.4106\n",
      "Epoch 24/25\n",
      "90000/90000 [==============================] - 699s - loss: 1.6097 - acc: 0.6013 - val_loss: 5.5349 - val_acc: 0.4126\n",
      "Epoch 25/25\n",
      "90000/90000 [==============================] - 698s - loss: 1.6669 - acc: 0.5895 - val_loss: 5.4491 - val_acc: 0.4082\n",
      "Train on 90000 samples, validate on 5000 samples\n",
      "Epoch 26/30\n",
      "90000/90000 [==============================] - 697s - loss: 1.7250 - acc: 0.5801 - val_loss: 5.3065 - val_acc: 0.4128\n",
      "Epoch 27/30\n",
      "90000/90000 [==============================] - 698s - loss: 1.8271 - acc: 0.5625 - val_loss: 4.8794 - val_acc: 0.4042\n",
      "Epoch 28/30\n",
      "90000/90000 [==============================] - 697s - loss: 1.9120 - acc: 0.5450 - val_loss: 4.6530 - val_acc: 0.3890\n",
      "Epoch 29/30\n",
      "90000/90000 [==============================] - 697s - loss: 2.0216 - acc: 0.5245 - val_loss: 4.6570 - val_acc: 0.3826\n",
      "Epoch 30/30\n",
      "90000/90000 [==============================] - 697s - loss: 2.1456 - acc: 0.5002 - val_loss: 5.3553 - val_acc: 0.3426\n"
     ]
    }
   ],
   "source": [
    "index= 0\n",
    "step = 5\n",
    "stop = 30\n",
    "\n",
    "while index < stop:\n",
    "    model.fit(x_train, y_train, batch_size=batch, initial_epoch=index, epochs=index+step, validation_data=(x_val, y_val), callbacks=[tbCallBack])\n",
    "    index += step\n",
    "    model.save_weights('data/models/model_coarse'+str(index))\n",
    "save_index = index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Most Recent Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_fine = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(model.layers)):\n",
    "    model.layers[i].trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning for Coarse Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_c = np.dot(y_train,fine2coarse)\n",
    "y_val_c = np.dot(y_val,fine2coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Conv2D(1024, 1, strides=1, padding='same', activation='elu')(model.layers[-8].output)\n",
    "net = Conv2D(1152, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Dropout(.6)(net)\n",
    "net = MaxPooling2D((2, 2), padding='same')(net)\n",
    "\n",
    "net = Flatten()(net)\n",
    "net = Dense(1152, activation='elu')(net)\n",
    "out_coarse = Dense(20, activation='softmax')(net)\n",
    "\n",
    "model_c = Model(inputs=in_layer,outputs=out_coarse)\n",
    "model_c.compile(optimizer= sgd_coarse, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "for i in range(len(model_c.layers)-1):\n",
    "    model_c.layers[i].set_weights(model.layers[i].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90000 samples, validate on 5000 samples\n",
      "Epoch 31/40\n",
      "90000/90000 [==============================] - 230s - loss: 1.2687 - acc: 0.6486 - val_loss: 3.8728 - val_acc: 0.5522\n",
      "Epoch 32/40\n",
      "90000/90000 [==============================] - 232s - loss: 1.1943 - acc: 0.6648 - val_loss: 3.8772 - val_acc: 0.5520\n",
      "Epoch 33/40\n",
      "90000/90000 [==============================] - 231s - loss: 1.1875 - acc: 0.6667 - val_loss: 3.7064 - val_acc: 0.5654\n",
      "Epoch 34/40\n",
      "90000/90000 [==============================] - 231s - loss: 1.1720 - acc: 0.6689 - val_loss: 3.7129 - val_acc: 0.5610\n",
      "Epoch 35/40\n",
      "90000/90000 [==============================] - 232s - loss: 1.1669 - acc: 0.6715 - val_loss: 3.6124 - val_acc: 0.5646\n",
      "Epoch 36/40\n",
      "90000/90000 [==============================] - 231s - loss: 1.1672 - acc: 0.6713 - val_loss: 3.7043 - val_acc: 0.5558\n",
      "Epoch 37/40\n",
      "90000/90000 [==============================] - 231s - loss: 1.1556 - acc: 0.6748 - val_loss: 3.7125 - val_acc: 0.5440\n",
      "Epoch 38/40\n",
      "90000/90000 [==============================] - 231s - loss: 1.1499 - acc: 0.6760 - val_loss: 3.5561 - val_acc: 0.5564\n",
      "Epoch 39/40\n",
      "90000/90000 [==============================] - 231s - loss: 1.1490 - acc: 0.6760 - val_loss: 3.6207 - val_acc: 0.5506\n",
      "Epoch 40/40\n",
      "90000/90000 [==============================] - 231s - loss: 1.1520 - acc: 0.6746 - val_loss: 3.6527 - val_acc: 0.5480\n"
     ]
    }
   ],
   "source": [
    "index = 30\n",
    "step = 10\n",
    "stop = 40\n",
    "\n",
    "while index < stop:\n",
    "    model_c.fit(x_train, y_train_c, batch_size=batch, initial_epoch=index, epochs=index+step, validation_data=(x_val, y_val_c), callbacks=[tbCallBack])\n",
    "    index += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90000 samples, validate on 5000 samples\n",
      "Epoch 41/50\n",
      "90000/90000 [==============================] - 231s - loss: 1.0175 - acc: 0.7034 - val_loss: 3.3435 - val_acc: 0.5900\n",
      "Epoch 42/50\n",
      "90000/90000 [==============================] - 231s - loss: 0.9962 - acc: 0.7072 - val_loss: 3.3375 - val_acc: 0.5892\n",
      "Epoch 43/50\n",
      "90000/90000 [==============================] - 231s - loss: 0.9812 - acc: 0.7106 - val_loss: 3.3343 - val_acc: 0.5922\n",
      "Epoch 44/50\n",
      "90000/90000 [==============================] - 232s - loss: 0.9842 - acc: 0.7113 - val_loss: 3.3335 - val_acc: 0.5882\n",
      "Epoch 45/50\n",
      "90000/90000 [==============================] - 231s - loss: 0.9725 - acc: 0.7118 - val_loss: 3.3180 - val_acc: 0.5854\n",
      "Epoch 46/50\n",
      "90000/90000 [==============================] - 231s - loss: 0.9668 - acc: 0.7142 - val_loss: 3.2924 - val_acc: 0.5854\n",
      "Epoch 47/50\n",
      "90000/90000 [==============================] - 231s - loss: 0.9676 - acc: 0.7132 - val_loss: 3.2755 - val_acc: 0.5900\n",
      "Epoch 48/50\n",
      "90000/90000 [==============================] - 231s - loss: 0.9615 - acc: 0.7137 - val_loss: 3.2926 - val_acc: 0.5878\n",
      "Epoch 49/50\n",
      "90000/90000 [==============================] - 231s - loss: 0.9622 - acc: 0.7123 - val_loss: 3.2664 - val_acc: 0.5858\n",
      "Epoch 50/50\n",
      "90000/90000 [==============================] - 231s - loss: 0.9576 - acc: 0.7146 - val_loss: 3.2840 - val_acc: 0.5874\n"
     ]
    }
   ],
   "source": [
    "model_c.compile(optimizer=sgd_fine, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "stop = 50\n",
    "\n",
    "while index < stop:\n",
    "    model_c.fit(x_train, y_train_c, batch_size=batch, initial_epoch=index, epochs=index+step, validation_data=(x_val, y_val_c), callbacks=[tbCallBack])\n",
    "    index += step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning for Fine Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Fine Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fine_model():\n",
    "    net = Conv2D(1024, 1, strides=1, padding='same', activation='elu')(model.layers[-8].output)\n",
    "    net = Conv2D(1152, 2, strides=1, padding='same', activation='elu')(net)\n",
    "    net = Dropout(.6)(net)\n",
    "    net = MaxPooling2D((2, 2), padding='same')(net)\n",
    "\n",
    "    net = Flatten()(net)\n",
    "    net = Dense(1152, activation='elu')(net)\n",
    "    out_fine = Dense(100, activation='softmax')(net)\n",
    "    model_fine = Model(inputs=in_layer,outputs=out_fine)\n",
    "    model_fine.compile(optimizer= sgd_coarse,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    for i in range(len(model_fine.layers)-1):\n",
    "        model_fine.layers[i].set_weights(model.layers[i].get_weights())\n",
    "    return model_fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_models = {'models' : [{} for i in range(coarse_categories)], 'yhf' : [{} for i in range(coarse_categories)]}\n",
    "for i in range(coarse_categories):\n",
    "    model_i = fine_model()\n",
    "    fine_models['models'][i] = model_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Fine Classifiers on Respective Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_error(y,yh):\n",
    "    # Threshold \n",
    "    yht = np.zeros(np.shape(yh))\n",
    "    yht[np.arange(len(yh)), yh.argmax(1)] = 1\n",
    "    # Evaluate Error\n",
    "    error = np.count_nonzero(np.count_nonzero(y-yht,1))/len(y)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4524 samples, validate on 238 samples\n",
      "Epoch 1/5\n",
      "4524/4524 [==============================] - 13s - loss: 1.3681 - acc: 0.5115 - val_loss: 5.4511 - val_acc: 0.3445\n",
      "Epoch 2/5\n",
      "4524/4524 [==============================] - 11s - loss: 1.2362 - acc: 0.5511 - val_loss: 5.4643 - val_acc: 0.3235\n",
      "Epoch 3/5\n",
      "4524/4524 [==============================] - 11s - loss: 1.1453 - acc: 0.5681 - val_loss: 5.6825 - val_acc: 0.3655\n",
      "Epoch 4/5\n",
      "4524/4524 [==============================] - 11s - loss: 1.1168 - acc: 0.5829 - val_loss: 5.4719 - val_acc: 0.3613\n",
      "Epoch 5/5\n",
      "4524/4524 [==============================] - 11s - loss: 1.1665 - acc: 0.5584 - val_loss: 5.5140 - val_acc: 0.3571\n",
      "Train on 4524 samples, validate on 238 samples\n",
      "Epoch 6/10\n",
      "4524/4524 [==============================] - 12s - loss: 0.9453 - acc: 0.6143 - val_loss: 5.3983 - val_acc: 0.3655\n",
      "Epoch 7/10\n",
      "4524/4524 [==============================] - 11s - loss: 0.9243 - acc: 0.6165 - val_loss: 5.3284 - val_acc: 0.3655\n",
      "Epoch 8/10\n",
      "4524/4524 [==============================] - 11s - loss: 0.9161 - acc: 0.6176 - val_loss: 5.3424 - val_acc: 0.3655\n",
      "Epoch 9/10\n",
      "4524/4524 [==============================] - 11s - loss: 0.8938 - acc: 0.6262 - val_loss: 5.4172 - val_acc: 0.3782\n",
      "Epoch 10/10\n",
      "4524/4524 [==============================] - 11s - loss: 0.9049 - acc: 0.6293 - val_loss: 5.3167 - val_acc: 0.3908\n",
      "Fine Classifier 0 Error: 0.6092436974789915\n",
      "Train on 4526 samples, validate on 237 samples\n",
      "Epoch 1/5\n",
      "4526/4526 [==============================] - 12s - loss: 0.9641 - acc: 0.6869 - val_loss: 5.3459 - val_acc: 0.4599\n",
      "Epoch 2/5\n",
      "4526/4526 [==============================] - 11s - loss: 0.7550 - acc: 0.7298 - val_loss: 5.2746 - val_acc: 0.4726\n",
      "Epoch 3/5\n",
      "4526/4526 [==============================] - 11s - loss: 0.7244 - acc: 0.7433 - val_loss: 5.3696 - val_acc: 0.4684\n",
      "Epoch 4/5\n",
      "4526/4526 [==============================] - 11s - loss: 0.6832 - acc: 0.7534 - val_loss: 5.4364 - val_acc: 0.4177\n",
      "Epoch 5/5\n",
      "4526/4526 [==============================] - 11s - loss: 0.6802 - acc: 0.7574 - val_loss: 5.4830 - val_acc: 0.4177\n",
      "Train on 4526 samples, validate on 237 samples\n",
      "Epoch 6/10\n",
      "4526/4526 [==============================] - 12s - loss: 0.6348 - acc: 0.7684 - val_loss: 5.1907 - val_acc: 0.5021\n",
      "Epoch 7/10\n",
      "4526/4526 [==============================] - 11s - loss: 0.5903 - acc: 0.7806 - val_loss: 5.1842 - val_acc: 0.4979\n",
      "Epoch 8/10\n",
      "4526/4526 [==============================] - 11s - loss: 0.5822 - acc: 0.7837 - val_loss: 5.2024 - val_acc: 0.4895\n",
      "Epoch 9/10\n",
      "4526/4526 [==============================] - 11s - loss: 0.5812 - acc: 0.7815 - val_loss: 5.1941 - val_acc: 0.5063\n",
      "Epoch 10/10\n",
      "4526/4526 [==============================] - 11s - loss: 0.5662 - acc: 0.7970 - val_loss: 5.1872 - val_acc: 0.5232\n",
      "Fine Classifier 1 Error: 0.4767932489451477\n",
      "Train on 4448 samples, validate on 276 samples\n",
      "Epoch 1/5\n",
      "4448/4448 [==============================] - 13s - loss: 1.0599 - acc: 0.6675 - val_loss: 4.5691 - val_acc: 0.4964\n",
      "Epoch 2/5\n",
      "4448/4448 [==============================] - 11s - loss: 0.8259 - acc: 0.7098 - val_loss: 4.4719 - val_acc: 0.5435\n",
      "Epoch 3/5\n",
      "4448/4448 [==============================] - 11s - loss: 0.7830 - acc: 0.7098 - val_loss: 4.4058 - val_acc: 0.5833\n",
      "Epoch 4/5\n",
      "4448/4448 [==============================] - 11s - loss: 0.7670 - acc: 0.7311 - val_loss: 4.4504 - val_acc: 0.5435\n",
      "Epoch 5/5\n",
      "4448/4448 [==============================] - 11s - loss: 0.7487 - acc: 0.7313 - val_loss: 4.4931 - val_acc: 0.5435\n",
      "Train on 4448 samples, validate on 276 samples\n",
      "Epoch 6/10\n",
      "4448/4448 [==============================] - 12s - loss: 0.6584 - acc: 0.7549 - val_loss: 4.3130 - val_acc: 0.5616\n",
      "Epoch 7/10\n",
      "4448/4448 [==============================] - 11s - loss: 0.6477 - acc: 0.7637 - val_loss: 4.3022 - val_acc: 0.5688\n",
      "Epoch 8/10\n",
      "4448/4448 [==============================] - 11s - loss: 0.6398 - acc: 0.7543 - val_loss: 4.3059 - val_acc: 0.5507\n",
      "Epoch 9/10\n",
      "4448/4448 [==============================] - 11s - loss: 0.6416 - acc: 0.7563 - val_loss: 4.2996 - val_acc: 0.5616\n",
      "Epoch 10/10\n",
      "4448/4448 [==============================] - 11s - loss: 0.6320 - acc: 0.7648 - val_loss: 4.2852 - val_acc: 0.5688\n",
      "Fine Classifier 2 Error: 0.4311594202898551\n",
      "Train on 4494 samples, validate on 253 samples\n",
      "Epoch 1/5\n",
      "4494/4494 [==============================] - 15s - loss: 0.9814 - acc: 0.6960 - val_loss: 4.2114 - val_acc: 0.5217\n",
      "Epoch 2/5\n",
      "4494/4494 [==============================] - 11s - loss: 0.7419 - acc: 0.7296 - val_loss: 4.3848 - val_acc: 0.4941\n",
      "Epoch 3/5\n",
      "4494/4494 [==============================] - 11s - loss: 0.7332 - acc: 0.7405 - val_loss: 4.4217 - val_acc: 0.5415\n",
      "Epoch 4/5\n",
      "4494/4494 [==============================] - 11s - loss: 0.7050 - acc: 0.7499 - val_loss: 4.2187 - val_acc: 0.4941\n",
      "Epoch 5/5\n",
      "4494/4494 [==============================] - 11s - loss: 0.7156 - acc: 0.7468 - val_loss: 4.1698 - val_acc: 0.5296\n",
      "Train on 4494 samples, validate on 253 samples\n",
      "Epoch 6/10\n",
      "4494/4494 [==============================] - 12s - loss: 0.6034 - acc: 0.7755 - val_loss: 4.0612 - val_acc: 0.5534\n",
      "Epoch 7/10\n",
      "4494/4494 [==============================] - 11s - loss: 0.6035 - acc: 0.7757 - val_loss: 4.0188 - val_acc: 0.5731\n",
      "Epoch 8/10\n",
      "4494/4494 [==============================] - 11s - loss: 0.5854 - acc: 0.7781 - val_loss: 4.0204 - val_acc: 0.5692\n",
      "Epoch 9/10\n",
      "4494/4494 [==============================] - 11s - loss: 0.5913 - acc: 0.7817 - val_loss: 4.0240 - val_acc: 0.5613\n",
      "Epoch 10/10\n",
      "4494/4494 [==============================] - 11s - loss: 0.5645 - acc: 0.7846 - val_loss: 4.0001 - val_acc: 0.5731\n",
      "Fine Classifier 3 Error: 0.4268774703557312\n",
      "Train on 4420 samples, validate on 290 samples\n",
      "Epoch 1/5\n",
      "4420/4420 [==============================] - 14s - loss: 0.7827 - acc: 0.7597 - val_loss: 4.2843 - val_acc: 0.5172\n",
      "Epoch 2/5\n",
      "4420/4420 [==============================] - 11s - loss: 0.5751 - acc: 0.8167 - val_loss: 5.0497 - val_acc: 0.4345\n",
      "Epoch 3/5\n",
      "4420/4420 [==============================] - 11s - loss: 0.5984 - acc: 0.8138 - val_loss: 4.2014 - val_acc: 0.5621\n",
      "Epoch 4/5\n",
      "4420/4420 [==============================] - 11s - loss: 0.5397 - acc: 0.8235 - val_loss: 4.7486 - val_acc: 0.4517\n",
      "Epoch 5/5\n",
      "4420/4420 [==============================] - 11s - loss: 0.5367 - acc: 0.8242 - val_loss: 4.2201 - val_acc: 0.5621\n",
      "Train on 4420 samples, validate on 290 samples\n",
      "Epoch 6/10\n",
      "4420/4420 [==============================] - 12s - loss: 0.4939 - acc: 0.8362 - val_loss: 4.0216 - val_acc: 0.5862\n",
      "Epoch 7/10\n",
      "4420/4420 [==============================] - 11s - loss: 0.4571 - acc: 0.8421 - val_loss: 4.0237 - val_acc: 0.5931\n",
      "Epoch 8/10\n",
      "4420/4420 [==============================] - 11s - loss: 0.4888 - acc: 0.8378 - val_loss: 3.9770 - val_acc: 0.5897\n",
      "Epoch 9/10\n",
      "4420/4420 [==============================] - 11s - loss: 0.4593 - acc: 0.8412 - val_loss: 3.9860 - val_acc: 0.5828\n",
      "Epoch 10/10\n",
      "4420/4420 [==============================] - 11s - loss: 0.4770 - acc: 0.8351 - val_loss: 3.9793 - val_acc: 0.5966\n",
      "Fine Classifier 4 Error: 0.40344827586206894\n",
      "Train on 4478 samples, validate on 261 samples\n",
      "Epoch 1/5\n",
      "4478/4478 [==============================] - 15s - loss: 0.8379 - acc: 0.7492 - val_loss: 3.2161 - val_acc: 0.6705\n",
      "Epoch 2/5\n",
      "4478/4478 [==============================] - 11s - loss: 0.6054 - acc: 0.7939 - val_loss: 3.2200 - val_acc: 0.6897\n",
      "Epoch 3/5\n",
      "4478/4478 [==============================] - 11s - loss: 0.5772 - acc: 0.8077 - val_loss: 3.1331 - val_acc: 0.6897\n",
      "Epoch 4/5\n",
      "4478/4478 [==============================] - 11s - loss: 0.5541 - acc: 0.8138 - val_loss: 3.2184 - val_acc: 0.6820\n",
      "Epoch 5/5\n",
      "4478/4478 [==============================] - 11s - loss: 0.5396 - acc: 0.8158 - val_loss: 3.2670 - val_acc: 0.6398\n",
      "Train on 4478 samples, validate on 261 samples\n",
      "Epoch 6/10\n",
      "4478/4478 [==============================] - 12s - loss: 0.4811 - acc: 0.8327 - val_loss: 3.1902 - val_acc: 0.6858\n",
      "Epoch 7/10\n",
      "4478/4478 [==============================] - 11s - loss: 0.4823 - acc: 0.8334 - val_loss: 3.1892 - val_acc: 0.6820\n",
      "Epoch 8/10\n",
      "4478/4478 [==============================] - 11s - loss: 0.4741 - acc: 0.8347 - val_loss: 3.1705 - val_acc: 0.6935\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4478/4478 [==============================] - 11s - loss: 0.4718 - acc: 0.8403 - val_loss: 3.1810 - val_acc: 0.6935\n",
      "Epoch 10/10\n",
      "4478/4478 [==============================] - 11s - loss: 0.4544 - acc: 0.8399 - val_loss: 3.1589 - val_acc: 0.6935\n",
      "Fine Classifier 5 Error: 0.3065134099616858\n",
      "Train on 4450 samples, validate on 275 samples\n",
      "Epoch 1/5\n",
      "4450/4450 [==============================] - 13s - loss: 1.0950 - acc: 0.6564 - val_loss: 6.0110 - val_acc: 0.4618\n",
      "Epoch 2/5\n",
      "4450/4450 [==============================] - 11s - loss: 0.9277 - acc: 0.6865 - val_loss: 5.9392 - val_acc: 0.4655\n",
      "Epoch 3/5\n",
      "4450/4450 [==============================] - 11s - loss: 0.8500 - acc: 0.7007 - val_loss: 5.9275 - val_acc: 0.4764\n",
      "Epoch 4/5\n",
      "4450/4450 [==============================] - 11s - loss: 0.8522 - acc: 0.7034 - val_loss: 5.8887 - val_acc: 0.4618\n",
      "Epoch 5/5\n",
      "4450/4450 [==============================] - 11s - loss: 0.8672 - acc: 0.6989 - val_loss: 6.0145 - val_acc: 0.4764\n",
      "Train on 4450 samples, validate on 275 samples\n",
      "Epoch 6/10\n",
      "4450/4450 [==============================] - 12s - loss: 0.7531 - acc: 0.7384 - val_loss: 5.9209 - val_acc: 0.4764\n",
      "Epoch 7/10\n",
      "4450/4450 [==============================] - 11s - loss: 0.7147 - acc: 0.7526 - val_loss: 5.9171 - val_acc: 0.4618\n",
      "Epoch 8/10\n",
      "4450/4450 [==============================] - 11s - loss: 0.7319 - acc: 0.7342 - val_loss: 5.8873 - val_acc: 0.4836\n",
      "Epoch 9/10\n",
      "4450/4450 [==============================] - 11s - loss: 0.7279 - acc: 0.7391 - val_loss: 5.8973 - val_acc: 0.4691\n",
      "Epoch 10/10\n",
      "4450/4450 [==============================] - 11s - loss: 0.7103 - acc: 0.7438 - val_loss: 5.8778 - val_acc: 0.4836\n",
      "Fine Classifier 6 Error: 0.5163636363636364\n",
      "Train on 4538 samples, validate on 231 samples\n",
      "Epoch 1/5\n",
      "4538/4538 [==============================] - 16s - loss: 0.8805 - acc: 0.7268 - val_loss: 4.1020 - val_acc: 0.5411\n",
      "Epoch 2/5\n",
      "4538/4538 [==============================] - 11s - loss: 0.7048 - acc: 0.7611 - val_loss: 4.0905 - val_acc: 0.5541\n",
      "Epoch 3/5\n",
      "4538/4538 [==============================] - 11s - loss: 0.6523 - acc: 0.7836 - val_loss: 4.2135 - val_acc: 0.5281\n",
      "Epoch 4/5\n",
      "4538/4538 [==============================] - 11s - loss: 0.6732 - acc: 0.7748 - val_loss: 4.0343 - val_acc: 0.5671\n",
      "Epoch 5/5\n",
      "4538/4538 [==============================] - 11s - loss: 0.6351 - acc: 0.7810 - val_loss: 4.1322 - val_acc: 0.5628\n",
      "Train on 4538 samples, validate on 231 samples\n",
      "Epoch 6/10\n",
      "4538/4538 [==============================] - 12s - loss: 0.5740 - acc: 0.8052 - val_loss: 4.1119 - val_acc: 0.5671\n",
      "Epoch 7/10\n",
      "4538/4538 [==============================] - 11s - loss: 0.5808 - acc: 0.7981 - val_loss: 4.0941 - val_acc: 0.5714\n",
      "Epoch 8/10\n",
      "4538/4538 [==============================] - 11s - loss: 0.5571 - acc: 0.8001 - val_loss: 4.0986 - val_acc: 0.5714\n",
      "Epoch 9/10\n",
      "4538/4538 [==============================] - 11s - loss: 0.5453 - acc: 0.8028 - val_loss: 4.0727 - val_acc: 0.5801\n",
      "Epoch 10/10\n",
      "4538/4538 [==============================] - 11s - loss: 0.5483 - acc: 0.8065 - val_loss: 4.0921 - val_acc: 0.5844\n",
      "Fine Classifier 7 Error: 0.4155844155844156\n",
      "Train on 4526 samples, validate on 237 samples\n",
      "Epoch 1/5\n",
      "4526/4526 [==============================] - 12s - loss: 0.8021 - acc: 0.7519 - val_loss: 4.2443 - val_acc: 0.4895\n",
      "Epoch 2/5\n",
      "4526/4526 [==============================] - 11s - loss: 0.6636 - acc: 0.7735 - val_loss: 4.1183 - val_acc: 0.5527\n",
      "Epoch 3/5\n",
      "4526/4526 [==============================] - 11s - loss: 0.6046 - acc: 0.8027 - val_loss: 4.0263 - val_acc: 0.5316\n",
      "Epoch 4/5\n",
      "4526/4526 [==============================] - 11s - loss: 0.6208 - acc: 0.7943 - val_loss: 4.1329 - val_acc: 0.5359\n",
      "Epoch 5/5\n",
      "4526/4526 [==============================] - 11s - loss: 0.5971 - acc: 0.8058 - val_loss: 4.1731 - val_acc: 0.5232\n",
      "Train on 4526 samples, validate on 237 samples\n",
      "Epoch 6/10\n",
      "4526/4526 [==============================] - 12s - loss: 0.5268 - acc: 0.8111 - val_loss: 4.0789 - val_acc: 0.5527\n",
      "Epoch 7/10\n",
      "4526/4526 [==============================] - 11s - loss: 0.5232 - acc: 0.8257 - val_loss: 4.0887 - val_acc: 0.5527\n",
      "Epoch 8/10\n",
      "4526/4526 [==============================] - 11s - loss: 0.5387 - acc: 0.8230 - val_loss: 4.0653 - val_acc: 0.5738\n",
      "Epoch 9/10\n",
      "4526/4526 [==============================] - 11s - loss: 0.5174 - acc: 0.8217 - val_loss: 4.0755 - val_acc: 0.5527\n",
      "Epoch 10/10\n",
      "4526/4526 [==============================] - 11s - loss: 0.5217 - acc: 0.8202 - val_loss: 4.0973 - val_acc: 0.5401\n",
      "Fine Classifier 8 Error: 0.459915611814346\n",
      "Train on 4512 samples, validate on 244 samples\n",
      "Epoch 1/5\n",
      "4512/4512 [==============================] - 14s - loss: 0.8045 - acc: 0.7553 - val_loss: 4.9289 - val_acc: 0.5041\n",
      "Epoch 2/5\n",
      "4512/4512 [==============================] - 11s - loss: 0.6094 - acc: 0.7923 - val_loss: 4.5532 - val_acc: 0.5451\n",
      "Epoch 3/5\n",
      "4512/4512 [==============================] - 11s - loss: 0.5794 - acc: 0.8039 - val_loss: 4.5426 - val_acc: 0.5656\n",
      "Epoch 4/5\n",
      "4512/4512 [==============================] - 11s - loss: 0.5386 - acc: 0.8145 - val_loss: 4.5614 - val_acc: 0.5820\n",
      "Epoch 5/5\n",
      "4512/4512 [==============================] - 11s - loss: 0.5334 - acc: 0.8240 - val_loss: 4.6216 - val_acc: 0.5492\n",
      "Train on 4512 samples, validate on 244 samples\n",
      "Epoch 6/10\n",
      "4512/4512 [==============================] - 12s - loss: 0.4889 - acc: 0.8351 - val_loss: 4.4652 - val_acc: 0.5697\n",
      "Epoch 7/10\n",
      "4512/4512 [==============================] - 11s - loss: 0.4449 - acc: 0.8446 - val_loss: 4.4552 - val_acc: 0.5902\n",
      "Epoch 8/10\n",
      "4512/4512 [==============================] - 11s - loss: 0.4716 - acc: 0.8369 - val_loss: 4.4378 - val_acc: 0.5943\n",
      "Epoch 9/10\n",
      "4512/4512 [==============================] - 11s - loss: 0.4479 - acc: 0.8420 - val_loss: 4.4515 - val_acc: 0.5779\n",
      "Epoch 10/10\n",
      "4512/4512 [==============================] - 11s - loss: 0.4618 - acc: 0.8371 - val_loss: 4.4362 - val_acc: 0.5902\n",
      "Fine Classifier 9 Error: 0.4098360655737705\n",
      "Train on 4470 samples, validate on 265 samples\n",
      "Epoch 1/5\n",
      "4470/4470 [==============================] - 15s - loss: 0.8493 - acc: 0.7535 - val_loss: 3.0188 - val_acc: 0.6566\n",
      "Epoch 2/5\n",
      "4470/4470 [==============================] - 11s - loss: 0.6389 - acc: 0.7864 - val_loss: 2.9657 - val_acc: 0.6943\n",
      "Epoch 3/5\n",
      "4470/4470 [==============================] - 11s - loss: 0.6137 - acc: 0.7946 - val_loss: 3.0591 - val_acc: 0.6566\n",
      "Epoch 4/5\n",
      "4470/4470 [==============================] - 11s - loss: 0.6006 - acc: 0.8016 - val_loss: 2.9542 - val_acc: 0.7094\n",
      "Epoch 5/5\n",
      "4470/4470 [==============================] - 11s - loss: 0.5932 - acc: 0.8038 - val_loss: 3.0887 - val_acc: 0.6528\n",
      "Train on 4470 samples, validate on 265 samples\n",
      "Epoch 6/10\n",
      "4470/4470 [==============================] - 12s - loss: 0.5166 - acc: 0.8219 - val_loss: 2.9619 - val_acc: 0.6906\n",
      "Epoch 7/10\n",
      "4470/4470 [==============================] - 11s - loss: 0.5081 - acc: 0.8246 - val_loss: 2.9705 - val_acc: 0.6868\n",
      "Epoch 8/10\n",
      "4470/4470 [==============================] - 11s - loss: 0.5243 - acc: 0.8192 - val_loss: 2.9552 - val_acc: 0.6981\n",
      "Epoch 9/10\n",
      "4470/4470 [==============================] - 11s - loss: 0.5128 - acc: 0.8237 - val_loss: 2.9599 - val_acc: 0.7057\n",
      "Epoch 10/10\n",
      "4470/4470 [==============================] - 11s - loss: 0.4929 - acc: 0.8233 - val_loss: 2.9603 - val_acc: 0.6981\n",
      "Fine Classifier 10 Error: 0.3018867924528302\n",
      "Train on 4540 samples, validate on 230 samples\n",
      "Epoch 1/5\n",
      "4540/4540 [==============================] - 16s - loss: 1.1126 - acc: 0.6302 - val_loss: 6.3042 - val_acc: 0.3696\n",
      "Epoch 2/5\n",
      "4540/4540 [==============================] - 11s - loss: 0.9254 - acc: 0.6758 - val_loss: 6.2428 - val_acc: 0.3783\n",
      "Epoch 3/5\n",
      "4540/4540 [==============================] - 11s - loss: 0.8782 - acc: 0.6846 - val_loss: 6.2385 - val_acc: 0.3348\n",
      "Epoch 4/5\n",
      "4540/4540 [==============================] - 11s - loss: 0.8978 - acc: 0.6786 - val_loss: 6.1679 - val_acc: 0.3826\n",
      "Epoch 5/5\n",
      "4540/4540 [==============================] - 11s - loss: 0.8596 - acc: 0.6852 - val_loss: 6.2157 - val_acc: 0.3913\n",
      "Train on 4540 samples, validate on 230 samples\n",
      "Epoch 6/10\n",
      "4540/4540 [==============================] - 12s - loss: 0.7661 - acc: 0.7271 - val_loss: 6.1444 - val_acc: 0.4217\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4540/4540 [==============================] - 11s - loss: 0.7471 - acc: 0.7238 - val_loss: 6.1818 - val_acc: 0.4043\n",
      "Epoch 8/10\n",
      "4540/4540 [==============================] - 11s - loss: 0.7719 - acc: 0.7240 - val_loss: 6.1484 - val_acc: 0.4261\n",
      "Epoch 9/10\n",
      "4540/4540 [==============================] - 11s - loss: 0.7305 - acc: 0.7311 - val_loss: 6.1477 - val_acc: 0.4174\n",
      "Epoch 10/10\n",
      "4540/4540 [==============================] - 11s - loss: 0.7423 - acc: 0.7300 - val_loss: 6.1217 - val_acc: 0.4261\n",
      "Fine Classifier 11 Error: 0.5739130434782609\n",
      "Train on 4502 samples, validate on 249 samples\n",
      "Epoch 1/5\n",
      "4502/4502 [==============================] - 15s - loss: 0.7717 - acc: 0.7654 - val_loss: 4.9607 - val_acc: 0.5141\n",
      "Epoch 2/5\n",
      "4502/4502 [==============================] - 11s - loss: 0.5712 - acc: 0.8127 - val_loss: 5.1192 - val_acc: 0.4980\n",
      "Epoch 3/5\n",
      "4502/4502 [==============================] - 11s - loss: 0.5284 - acc: 0.8152 - val_loss: 4.8457 - val_acc: 0.5181\n",
      "Epoch 4/5\n",
      "4502/4502 [==============================] - 11s - loss: 0.5364 - acc: 0.8227 - val_loss: 4.9307 - val_acc: 0.5181\n",
      "Epoch 5/5\n",
      "4502/4502 [==============================] - 11s - loss: 0.5229 - acc: 0.8294 - val_loss: 5.0740 - val_acc: 0.5141\n",
      "Train on 4502 samples, validate on 249 samples\n",
      "Epoch 6/10\n",
      "4502/4502 [==============================] - 12s - loss: 0.4668 - acc: 0.8407 - val_loss: 4.9141 - val_acc: 0.5301\n",
      "Epoch 7/10\n",
      "4502/4502 [==============================] - 11s - loss: 0.4324 - acc: 0.8445 - val_loss: 4.8960 - val_acc: 0.5221\n",
      "Epoch 8/10\n",
      "4502/4502 [==============================] - 11s - loss: 0.4441 - acc: 0.8474 - val_loss: 4.8968 - val_acc: 0.5422\n",
      "Epoch 9/10\n",
      "4502/4502 [==============================] - 11s - loss: 0.4633 - acc: 0.8356 - val_loss: 4.8989 - val_acc: 0.5341\n",
      "Epoch 10/10\n",
      "4502/4502 [==============================] - 11s - loss: 0.4370 - acc: 0.8425 - val_loss: 4.8820 - val_acc: 0.5341\n",
      "Fine Classifier 12 Error: 0.46586345381526106\n",
      "Train on 4542 samples, validate on 229 samples\n",
      "Epoch 1/5\n",
      "4542/4542 [==============================] - 14s - loss: 0.8163 - acc: 0.7490 - val_loss: 3.3408 - val_acc: 0.5764\n",
      "Epoch 2/5\n",
      "4542/4542 [==============================] - 11s - loss: 0.6195 - acc: 0.7827 - val_loss: 3.3553 - val_acc: 0.5983\n",
      "Epoch 3/5\n",
      "4542/4542 [==============================] - 11s - loss: 0.5943 - acc: 0.7917 - val_loss: 3.2073 - val_acc: 0.6288\n",
      "Epoch 4/5\n",
      "4542/4542 [==============================] - 11s - loss: 0.5485 - acc: 0.8082 - val_loss: 3.0915 - val_acc: 0.6376\n",
      "Epoch 5/5\n",
      "4542/4542 [==============================] - 11s - loss: 0.5519 - acc: 0.8003 - val_loss: 3.1695 - val_acc: 0.6332\n",
      "Train on 4542 samples, validate on 229 samples\n",
      "Epoch 6/10\n",
      "4542/4542 [==============================] - 12s - loss: 0.4820 - acc: 0.8298 - val_loss: 3.1531 - val_acc: 0.6157\n",
      "Epoch 7/10\n",
      "4542/4542 [==============================] - 11s - loss: 0.4858 - acc: 0.8230 - val_loss: 3.1368 - val_acc: 0.6376\n",
      "Epoch 8/10\n",
      "4542/4542 [==============================] - 11s - loss: 0.4679 - acc: 0.8274 - val_loss: 3.1420 - val_acc: 0.6070\n",
      "Epoch 9/10\n",
      "4542/4542 [==============================] - 11s - loss: 0.4773 - acc: 0.8247 - val_loss: 3.1198 - val_acc: 0.6245\n",
      "Epoch 10/10\n",
      "4542/4542 [==============================] - 11s - loss: 0.4921 - acc: 0.8316 - val_loss: 3.1107 - val_acc: 0.6201\n",
      "Fine Classifier 13 Error: 0.3799126637554585\n",
      "Train on 4484 samples, validate on 258 samples\n",
      "Epoch 1/5\n",
      "4484/4484 [==============================] - 12s - loss: 1.9045 - acc: 0.3709 - val_loss: 8.0939 - val_acc: 0.1899\n",
      "Epoch 2/5\n",
      "4484/4484 [==============================] - 11s - loss: 1.8776 - acc: 0.3947 - val_loss: 6.3107 - val_acc: 0.2054\n",
      "Epoch 3/5\n",
      "4484/4484 [==============================] - 11s - loss: 1.7860 - acc: 0.3836 - val_loss: 6.2777 - val_acc: 0.2054\n",
      "Epoch 4/5\n",
      "4484/4484 [==============================] - 11s - loss: 1.7464 - acc: 0.3874 - val_loss: 6.3755 - val_acc: 0.1938\n",
      "Epoch 5/5\n",
      "4484/4484 [==============================] - 11s - loss: 1.7710 - acc: 0.3938 - val_loss: 5.6907 - val_acc: 0.2171\n",
      "Train on 4484 samples, validate on 258 samples\n",
      "Epoch 6/10\n",
      "4484/4484 [==============================] - 12s - loss: 1.4018 - acc: 0.4454 - val_loss: 5.2231 - val_acc: 0.2674\n",
      "Epoch 7/10\n",
      "4484/4484 [==============================] - 11s - loss: 1.3579 - acc: 0.4567 - val_loss: 5.2245 - val_acc: 0.2829\n",
      "Epoch 8/10\n",
      "4484/4484 [==============================] - 11s - loss: 1.3230 - acc: 0.4639 - val_loss: 5.2363 - val_acc: 0.2713\n",
      "Epoch 9/10\n",
      "4484/4484 [==============================] - 11s - loss: 1.3176 - acc: 0.4739 - val_loss: 5.2456 - val_acc: 0.2674\n",
      "Epoch 10/10\n",
      "4484/4484 [==============================] - 11s - loss: 1.2989 - acc: 0.4804 - val_loss: 5.2889 - val_acc: 0.2713\n",
      "Fine Classifier 14 Error: 0.7286821705426356\n",
      "Train on 4568 samples, validate on 216 samples\n",
      "Epoch 1/5\n",
      "4568/4568 [==============================] - 14s - loss: 1.1622 - acc: 0.6230 - val_loss: 5.3684 - val_acc: 0.4352\n",
      "Epoch 2/5\n",
      "4568/4568 [==============================] - 11s - loss: 0.9133 - acc: 0.6841 - val_loss: 5.2847 - val_acc: 0.4491\n",
      "Epoch 3/5\n",
      "4568/4568 [==============================] - 11s - loss: 0.8910 - acc: 0.6832 - val_loss: 5.7220 - val_acc: 0.3426\n",
      "Epoch 4/5\n",
      "4568/4568 [==============================] - 11s - loss: 0.8609 - acc: 0.6907 - val_loss: 5.3862 - val_acc: 0.4028\n",
      "Epoch 5/5\n",
      "4568/4568 [==============================] - 11s - loss: 0.8302 - acc: 0.7115 - val_loss: 5.4716 - val_acc: 0.4398\n",
      "Train on 4568 samples, validate on 216 samples\n",
      "Epoch 6/10\n",
      "4568/4568 [==============================] - 12s - loss: 0.7707 - acc: 0.7194 - val_loss: 5.3740 - val_acc: 0.4213\n",
      "Epoch 7/10\n",
      "4568/4568 [==============================] - 11s - loss: 0.7497 - acc: 0.7323 - val_loss: 5.3790 - val_acc: 0.4213\n",
      "Epoch 8/10\n",
      "4568/4568 [==============================] - 11s - loss: 0.7396 - acc: 0.7360 - val_loss: 5.3850 - val_acc: 0.4074\n",
      "Epoch 9/10\n",
      "4568/4568 [==============================] - 11s - loss: 0.7358 - acc: 0.7342 - val_loss: 5.3320 - val_acc: 0.4491\n",
      "Epoch 10/10\n",
      "4568/4568 [==============================] - 11s - loss: 0.7420 - acc: 0.7325 - val_loss: 5.3482 - val_acc: 0.4398\n",
      "Fine Classifier 15 Error: 0.5601851851851852\n",
      "Train on 4462 samples, validate on 269 samples\n",
      "Epoch 1/5\n",
      "4462/4462 [==============================] - 13s - loss: 1.2962 - acc: 0.5652 - val_loss: 4.7140 - val_acc: 0.3829\n",
      "Epoch 2/5\n",
      "4462/4462 [==============================] - 11s - loss: 1.0879 - acc: 0.5932 - val_loss: 4.8432 - val_acc: 0.3606\n",
      "Epoch 3/5\n",
      "4462/4462 [==============================] - 11s - loss: 1.0876 - acc: 0.6147 - val_loss: 4.9667 - val_acc: 0.2788\n",
      "Epoch 4/5\n",
      "4462/4462 [==============================] - 11s - loss: 1.0431 - acc: 0.6130 - val_loss: 4.7778 - val_acc: 0.3569\n",
      "Epoch 5/5\n",
      "4462/4462 [==============================] - 11s - loss: 1.0308 - acc: 0.6159 - val_loss: 4.6640 - val_acc: 0.3941\n",
      "Train on 4462 samples, validate on 269 samples\n",
      "Epoch 6/10\n",
      "4462/4462 [==============================] - 12s - loss: 0.8971 - acc: 0.6694 - val_loss: 4.5529 - val_acc: 0.4126\n",
      "Epoch 7/10\n",
      "4462/4462 [==============================] - 11s - loss: 0.8977 - acc: 0.6544 - val_loss: 4.5563 - val_acc: 0.4052\n",
      "Epoch 8/10\n",
      "4462/4462 [==============================] - 11s - loss: 0.8720 - acc: 0.6593 - val_loss: 4.5737 - val_acc: 0.4275\n",
      "Epoch 9/10\n",
      "4462/4462 [==============================] - 11s - loss: 0.8668 - acc: 0.6674 - val_loss: 4.5600 - val_acc: 0.4275\n",
      "Epoch 10/10\n",
      "4462/4462 [==============================] - 11s - loss: 0.8814 - acc: 0.6714 - val_loss: 4.5631 - val_acc: 0.4164\n",
      "Fine Classifier 16 Error: 0.5836431226765799\n",
      "Train on 4462 samples, validate on 269 samples\n",
      "Epoch 1/5\n",
      "4462/4462 [==============================] - 12s - loss: 1.2636 - acc: 0.5784 - val_loss: 4.1198 - val_acc: 0.4498\n",
      "Epoch 2/5\n",
      "4462/4462 [==============================] - 11s - loss: 1.0834 - acc: 0.6123 - val_loss: 3.8924 - val_acc: 0.4796\n",
      "Epoch 3/5\n",
      "4462/4462 [==============================] - 11s - loss: 1.0294 - acc: 0.6347 - val_loss: 3.8261 - val_acc: 0.4833\n",
      "Epoch 4/5\n",
      "4462/4462 [==============================] - 11s - loss: 0.9859 - acc: 0.6484 - val_loss: 3.7467 - val_acc: 0.4907\n",
      "Epoch 5/5\n",
      "4462/4462 [==============================] - 11s - loss: 1.0236 - acc: 0.6333 - val_loss: 3.7724 - val_acc: 0.5019\n",
      "Train on 4462 samples, validate on 269 samples\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4462/4462 [==============================] - 12s - loss: 0.8677 - acc: 0.6797 - val_loss: 3.6947 - val_acc: 0.5465\n",
      "Epoch 7/10\n",
      "4462/4462 [==============================] - 11s - loss: 0.8332 - acc: 0.6842 - val_loss: 3.7074 - val_acc: 0.5502\n",
      "Epoch 8/10\n",
      "4462/4462 [==============================] - 11s - loss: 0.8291 - acc: 0.6934 - val_loss: 3.6796 - val_acc: 0.5204\n",
      "Epoch 9/10\n",
      "4462/4462 [==============================] - 11s - loss: 0.8464 - acc: 0.6806 - val_loss: 3.7036 - val_acc: 0.5167\n",
      "Epoch 10/10\n",
      "4462/4462 [==============================] - 11s - loss: 0.8339 - acc: 0.6851 - val_loss: 3.7270 - val_acc: 0.5130\n",
      "Fine Classifier 17 Error: 0.48698884758364314\n",
      "Train on 4492 samples, validate on 254 samples\n",
      "Epoch 1/5\n",
      "4492/4492 [==============================] - 13s - loss: 0.7663 - acc: 0.7567 - val_loss: 3.7631 - val_acc: 0.5866\n",
      "Epoch 2/5\n",
      "4492/4492 [==============================] - 11s - loss: 0.5795 - acc: 0.7974 - val_loss: 3.8636 - val_acc: 0.5866\n",
      "Epoch 3/5\n",
      "4492/4492 [==============================] - 11s - loss: 0.5750 - acc: 0.7936 - val_loss: 3.8421 - val_acc: 0.5984\n",
      "Epoch 4/5\n",
      "4492/4492 [==============================] - 11s - loss: 0.5430 - acc: 0.8021 - val_loss: 3.6111 - val_acc: 0.6614\n",
      "Epoch 5/5\n",
      "4492/4492 [==============================] - 11s - loss: 0.5168 - acc: 0.8099 - val_loss: 3.6445 - val_acc: 0.6693\n",
      "Train on 4492 samples, validate on 254 samples\n",
      "Epoch 6/10\n",
      "4492/4492 [==============================] - 12s - loss: 0.4771 - acc: 0.8244 - val_loss: 3.6075 - val_acc: 0.6654\n",
      "Epoch 7/10\n",
      "4492/4492 [==============================] - 11s - loss: 0.4746 - acc: 0.8308 - val_loss: 3.6127 - val_acc: 0.6693\n",
      "Epoch 8/10\n",
      "4492/4492 [==============================] - 11s - loss: 0.4709 - acc: 0.8186 - val_loss: 3.6108 - val_acc: 0.6732\n",
      "Epoch 9/10\n",
      "4492/4492 [==============================] - 11s - loss: 0.4261 - acc: 0.8379 - val_loss: 3.6030 - val_acc: 0.6929\n",
      "Epoch 10/10\n",
      "4492/4492 [==============================] - 11s - loss: 0.4312 - acc: 0.8397 - val_loss: 3.5856 - val_acc: 0.7008\n",
      "Fine Classifier 18 Error: 0.2992125984251969\n",
      "Train on 4562 samples, validate on 219 samples\n",
      "Epoch 1/5\n",
      "4562/4562 [==============================] - 15s - loss: 0.5973 - acc: 0.8290 - val_loss: 3.5616 - val_acc: 0.6804\n",
      "Epoch 2/5\n",
      "4562/4562 [==============================] - 11s - loss: 0.4097 - acc: 0.8696 - val_loss: 3.5331 - val_acc: 0.6712\n",
      "Epoch 3/5\n",
      "4562/4562 [==============================] - 11s - loss: 0.3818 - acc: 0.8709 - val_loss: 3.4871 - val_acc: 0.6941\n",
      "Epoch 4/5\n",
      "4562/4562 [==============================] - 11s - loss: 0.3600 - acc: 0.8803 - val_loss: 3.4596 - val_acc: 0.6712\n",
      "Epoch 5/5\n",
      "4562/4562 [==============================] - 11s - loss: 0.3725 - acc: 0.8775 - val_loss: 3.4145 - val_acc: 0.6941\n",
      "Train on 4562 samples, validate on 219 samples\n",
      "Epoch 6/10\n",
      "4562/4562 [==============================] - 12s - loss: 0.2986 - acc: 0.8972 - val_loss: 3.3756 - val_acc: 0.7032\n",
      "Epoch 7/10\n",
      "4562/4562 [==============================] - 11s - loss: 0.3003 - acc: 0.8943 - val_loss: 3.3706 - val_acc: 0.6986\n",
      "Epoch 8/10\n",
      "4562/4562 [==============================] - 11s - loss: 0.3013 - acc: 0.8976 - val_loss: 3.3628 - val_acc: 0.6849\n",
      "Epoch 9/10\n",
      "4562/4562 [==============================] - 11s - loss: 0.3077 - acc: 0.8924 - val_loss: 3.3824 - val_acc: 0.6941\n",
      "Epoch 10/10\n",
      "4562/4562 [==============================] - 11s - loss: 0.3090 - acc: 0.8943 - val_loss: 3.3680 - val_acc: 0.6895\n",
      "Fine Classifier 19 Error: 0.3105022831050228\n"
     ]
    }
   ],
   "source": [
    "for i in range(coarse_categories):\n",
    "    index= 0\n",
    "    step = 5\n",
    "    stop = 5\n",
    "    \n",
    "    # Get all training data for the coarse category\n",
    "    ix = np.where([(y_train[:,j]==1) for j in [k for k, e in enumerate(fine2coarse[:,i]) if e != 0]])[1]\n",
    "    x_tix = x_train[ix]\n",
    "    y_tix = y_train[ix]\n",
    "    \n",
    "    # Get all validation data for the coarse category\n",
    "    ix_v = np.where([(y_val[:,j]==1) for j in [k for k, e in enumerate(fine2coarse[:,i]) if e != 0]])[1]\n",
    "    x_vix = x_val[ix_v]\n",
    "    y_vix = y_val[ix_v]\n",
    "    \n",
    "    while index < stop:\n",
    "        fine_models['models'][i].fit(x_tix, y_tix, batch_size=batch, initial_epoch=index, epochs=index+step, validation_data=(x_vix, y_vix))\n",
    "        index += step\n",
    "    \n",
    "    fine_models['models'][i].compile(optimizer=sgd_fine, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    stop = 10\n",
    "\n",
    "    while index < stop:\n",
    "        fine_models['models'][i].fit(x_tix, y_tix, batch_size=batch, initial_epoch=index, epochs=index+step, validation_data=(x_vix, y_vix))\n",
    "        index += step\n",
    "        \n",
    "    yh_f = fine_models['models'][i].predict(x_val[ix_v], batch_size=batch)\n",
    "    print('Fine Classifier '+str(i)+' Error: '+str(get_error(y_val[ix_v],yh_f))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Probabilistic Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_hdcnn(X, y):\n",
    "    yh = np.zeros(np.shape(y))\n",
    "    \n",
    "    yh_s = model.predict(X, batch_size=batch)\n",
    "    \n",
    "    print('Single Classifier Error: '+str(get_error(y,yh_s)))\n",
    "    \n",
    "    yh_c = model_c.predict(X, batch_size=batch)\n",
    "    y_c = np.dot(y,fine2coarse)\n",
    "    \n",
    "    print('Coarse Classifier Error: '+str(get_error(y_c,yh_c)))\n",
    "\n",
    "    for i in range(coarse_categories):\n",
    "        if i%5 == 0:\n",
    "            print(\"Evaluating Fine Classifier: \", str(i))\n",
    "        #fine_models['yhf'][i] = fine_models['models'][i].predict(X, batch_size=batch)\n",
    "        yh += np.multiply(yh_c[:,i].reshape((len(y)),1), fine_models['yhf'][i])\n",
    "    \n",
    "    print('Overall Error: '+str(get_error(y,yh)))\n",
    "    return yh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Classifier Error: 0.6574\n",
      "Coarse Classifier Error: 0.4126\n",
      "Evaluating Fine Classifier:  0\n",
      "Evaluating Fine Classifier:  5\n",
      "Evaluating Fine Classifier:  10\n",
      "Evaluating Fine Classifier:  15\n",
      "Overall Error: 0.604\n"
     ]
    }
   ],
   "source": [
    "yh = eval_hdcnn(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
