{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchically Deep Convolutional Neural Network For Image Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as kr\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.datasets import cifar100\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from random import randint\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Global Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The number of coarse categories\n",
    "coarse_categories = 20\n",
    "\n",
    "# The number of fine categories\n",
    "fine_categories = 100\n",
    "\n",
    "# The threshold percentage in thresholding layer\n",
    "sigma = .01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Preprocess Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Cifar100 Data Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X, y_c), (x_test, y_c_test) = cifar100.load_data(label_mode='coarse')\n",
    "(X, y), (x_test, y_test) = cifar100.load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Partition data into only 10 fine categories and 2 coarse categories\n",
    "index = np.where((y_c[:,0] == 0) | (y_c[:,0] == 1))[0]\n",
    "y = np.array([y[j] for j in index])\n",
    "y_c = np.array([y_c[j] for j in index])\n",
    "X = np.array([X[j] for j in index])\n",
    "\n",
    "index = np.where((y_c_test[:,0] == 0) | (y_c_test[:,0] == 1))[0]\n",
    "y_test = np.array([y_test[j] for j in index])\n",
    "y_c_test = np.array([y_c_test[j] for j in index])\n",
    "x_test = np.array([x_test[j] for j in index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The new number of coarse categories\n",
    "coarse_categories = 2\n",
    "\n",
    "# The new number of fine categories\n",
    "fine_categories = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fine-To-Coarse Mapping**\n",
    "\n",
    "(Ideally, this would be done through spectral clustering as opposed to hard-coding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fine2coarse = np.zeros((coarse_categories,int(fine_categories/coarse_categories)))\n",
    "for i in range(coarse_categories):\n",
    "    index = np.where(y_c[:,0] == i)[0]\n",
    "    fine_cat = np.unique([y[j,0] for j in index])\n",
    "    fine2coarse[i] = fine_cat  \n",
    "y_c = 0; # Clear y_c in interest of saving mem\n",
    "y_c_test=0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X = X[:10]\n",
    "#y = y[:10]\n",
    "## This is just for testing purposes, as is the n_values = 100 in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#    Title: One Hot Encoding\n",
    "################################################################################\n",
    "#    Description: \n",
    "#        This function extends a matrix to one-hot encoding\n",
    "#    \n",
    "#    Parameters:\n",
    "#        y    Array of label values\n",
    "# \n",
    "#    Returns:\n",
    "#        y_new    One hot encoded array of labels\n",
    "################################################################################\n",
    "def one_hot(y):\n",
    "    n_values = 100#np.max(y) + 1\n",
    "    y_new = np.eye(n_values)[y[:,0]]\n",
    "    return y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=one_hot(y)\n",
    "y_test=one_hot(y_test)\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply ZCA Whitening**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Center data\n",
    "X = X - 128\n",
    "x_train = x_train - 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#    Title: ZCA\n",
    "################################################################################\n",
    "#    Description: \n",
    "#        This function applies ZCA Whitening to the image set\n",
    "#    \n",
    "#    Parameters:\n",
    "#        x_1           Array of MxNxC images to compute the ZCA Whitening\n",
    "#        x_2           Array of MxNxC images to apply the ZCA transform\n",
    "#        num_batch    Number of batches to do the computation\n",
    "# \n",
    "#    Returns:\n",
    "#        An array of MxNxC zca whitened images\n",
    "################################################################################\n",
    "def zca(x_1, x_2, epsilon=1e-5):\n",
    "        \n",
    "    with tf.name_scope('ZCA'):\n",
    "        \n",
    "        x1 = tf.placeholder(tf.float64, shape=np.shape(x_1), name='placeholder_x1')\n",
    "        x2 = tf.placeholder(tf.float64, shape=np.shape(x_2), name='placeholder_x2')\n",
    "        \n",
    "        flatx = tf.cast(tf.reshape(x1, (-1, np.prod(x_1.shape[-3:])),name=\"reshape_flat\"),tf.float64,name=\"flatx\")\n",
    "        sigma = tf.tensordot(tf.transpose(flatx),flatx, 1,name=\"sigma\") / tf.cast(tf.shape(flatx)[0],tf.float64) ### N-1 or N?\n",
    "        s, u, v = tf.svd(sigma,name=\"svd\")\n",
    "        pc = tf.tensordot(tf.tensordot(u,tf.diag(1. / tf.sqrt(s+epsilon)),1,name=\"inner_dot\"),tf.transpose(u),1, name=\"pc\")\n",
    "        \n",
    "        net1 = tf.tensordot(flatx, pc,1,name=\"whiten1\")\n",
    "        net1 = tf.reshape(net1,np.shape(x_1), name=\"output1\")\n",
    "        \n",
    "        flatx2 = tf.cast(tf.reshape(x2, (-1, np.prod(x_2.shape[-3:])),name=\"reshape_flat2\"),tf.float64,name=\"flatx2\")\n",
    "        net2 = tf.tensordot(flatx2, pc,1,name=\"whiten2\")\n",
    "        net2 = tf.reshape(net2,np.shape(x_2), name=\"output2\")\n",
    "        \n",
    "    with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            x_1,x_2 = sess.run([net1,net2], feed_dict={x1: x_1, x2: x_2})    \n",
    "    return x_1,x_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = time.time()\n",
    "X,x_test = zca(X,x_test)\n",
    "time2 = time.time()\n",
    "print('Time Elapsed - ZCA Whitening: '+str(time2-time1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resize Images to be compatible with VGG16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#    Title: Preprocess Images\n",
    "################################################################################\n",
    "#    Description: \n",
    "#        This function resizes 32x32x3 images to 128x128x3 by adding padding\n",
    "#    \n",
    "#    Parameters:\n",
    "#        X            Array of 32x32x3 Images\n",
    "#        num_batch    Number of batches to do the computation\n",
    "# \n",
    "#    Returns:\n",
    "#        A 224x224 set of images\n",
    "################################################################################\n",
    "def resize(X, num_batch=1):\n",
    "    l = len(X)\n",
    "    d=int(l/num_batch)\n",
    "    X_new = np.zeros((l,224,224,3)).astype(np.int8)\n",
    "    ind = 0\n",
    "    for i in range (num_batch):\n",
    "        end = ind+d\n",
    "        if i==num_batch-1:\n",
    "            end = l;\n",
    "        x_batch = X[ind:end]\n",
    "        net = tf.image.resize_images(x_batch, size=(256,256))\n",
    "        net = tf.random_crop(net, ((end-ind),224,224,3))\n",
    "        with tf.Session() as sess:\n",
    "                X_new[ind:end] = sess.run(net)\n",
    "        ind = ind + d\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = time.time()\n",
    "X = resize(X,10)\n",
    "#x_test = resize(x_test) #Commented only for testing purposes\n",
    "time2 = time.time()\n",
    "print('Time Elapsed - Resizing: '+str(time2-time1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Training set into Training and Validation sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=.1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coarse Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import VGG16 Pretrained on Imagenet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citation credit for VGG16 model to:\n",
    "\n",
    "Simonyan, Karen, and Andrew Zisserman. “Very Deep Convolutional Networks for Large-Scale Image Recognition.” [1409.1556] Very Deep Convolutional Networks for Large-Scale Image Recognition, 10 Apr. 2015, arxiv.org/abs/1409.1556."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv3D\n",
    "from keras.models import Model\n",
    "in_layer = Input(shape=(224, 224, 3), dtype='float32', name='main_input')\n",
    "model = VGG16(include_top=True, weights='imagenet', input_tensor=in_layer, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modify Model for Cifar100**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_coarse = Dense(100, activation='softmax')(model.layers[-2].output)\n",
    "model = Model(inputs=in_layer,outputs=out_coarse)\n",
    "model.compile(optimizer= 'adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index= 0\n",
    "step = 2\n",
    "stop = 10\n",
    "\n",
    "while index < stop:\n",
    "    model.fit(x_train, y_train, batch_size=32, initial_epoch=index, epochs=index+step, validation_data=(x_val, y_val))\n",
    "    index += step\n",
    "    model.save_weights('data/models/model_coarse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Most Recent Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('data/models/model_coarse_'+str(stop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Fine Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainable_index = 17\n",
    "\n",
    "for i in range(len(model.layers)):\n",
    "    if i<trainable_index:\n",
    "        model.layers[i].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fine_model():\n",
    "    out_fine = Dense(fine_categories, activation='softmax')(model.layers[-2].output)\n",
    "    model_fine = Model(inputs=in_layer,outputs=out_fine)\n",
    "    model_fine.compile(optimizer= 'adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model_fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fine_models = {'models' : [{} for i in range(coarse_categories)]}\n",
    "for i in range(coarse_categories):\n",
    "    model_i = fine_model()\n",
    "    fine_models['models'][i] = model_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Fine Classifiers on Respective Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(coarse_categories):\n",
    "    print(\"Training Fine Classifier: \", str(i))\n",
    "    \n",
    "    index= 0\n",
    "    step = 2\n",
    "    stop = 10  # Set to this only for testing purposes, change later\n",
    "    \n",
    "    # Get all training data for the coarse category\n",
    "    ind = np.where([(y_train[:,int(fine2coarse[i,j])]==1) for j in range(int(fine_categories/coarse_categories))])[1]\n",
    "    y_i = np.array([y_train[j] for j in ind])\n",
    "    x_i = np.array([x_train[j] for j in ind])\n",
    "    print(np.shape(y_i))\n",
    "    print(np.shape(x_i))\n",
    "    \n",
    "    # Get all validation data for the coarse category\n",
    "    indv = np.where([(y_val[:,int(fine2coarse[i,j])]==1) for j in range(int(fine_categories/coarse_categories))])[1]\n",
    "    y_iv = np.array([y_val[j] for j in indv])\n",
    "    x_iv = np.array([x_val[j] for j in indv])\n",
    "    print(np.shape(y_iv))\n",
    "    print(np.shape(x_iv))\n",
    "    \n",
    "    if (np.shape(x_i)[0]>0)&(np.shape(x_iv)[0]>0):\n",
    "        while index < stop:\n",
    "            fine_models['models'][i].fit(x_i, y_i, batch_size=2, initial_epoch=index, epochs=index+step, validation_data=(x_iv, y_iv))\n",
    "            index += step\n",
    "            fine_models['models'][i].save_weights('data/models/model_fine_'+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Probabilistic Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
