{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks For Image Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import os\n",
    "\n",
    "# To make make consistent across code blocks\n",
    "rnd.seed(42)\n",
    "\n",
    "# Ploting\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Saving Parameters\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"cnn\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"data\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import keras as kr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_one_hot(X):\n",
    "    n_values = np.max(X) + 1\n",
    "    y = np.eye(n_values)[X[:,0]]\n",
    "    return y\n",
    "\n",
    "y_train_adj = to_one_hot(y_train)\n",
    "y_test_adj  = to_one_hot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coarse Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Defining Structure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indep_layers(X, set_index):\n",
    "    s = '__shared_layer_'\n",
    "    net = Conv2D(32, (4, 4), strides=(1, 1), padding='same', activation='elu', name=set_index+s+str(1))(X)\n",
    "    net = Conv2D(32, (4, 4), strides=(1, 1), padding='same', activation='elu', name=set_index+s+str(2))(net)\n",
    "    net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "    net = Conv2D(64, (2, 2), strides=(1, 1), padding='same', activation='elu', name=set_index+s+str(3))(net)\n",
    "    net = Conv2D(64, (2, 2), strides=(1, 1), padding='same', activation='elu', name=set_index+s+str(4))(net)\n",
    "    net = Conv2D(64, (2, 2), strides=(1, 1), padding='same', activation='elu', name=set_index+s+str(5))(net)\n",
    "    net = Flatten()(net)\n",
    "\n",
    "    net = Dense(256, activation='elu', name=set_index+s+str(6))(net)\n",
    "    net = Dropout(0.50)(net)\n",
    "    net = Dense(256, activation='elu', name=set_index+s+str(7))(net)\n",
    "    net = Dropout(0.50)(net)\n",
    "    net = Dense(100, activation='softmax')(net)\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Input, Flatten, Dense, Dropout, Multiply, Add, Dot, RepeatVector, Reshape\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Model\n",
    "\n",
    "coarse_categories = 20\n",
    "fine_categories = 100\n",
    "sigma = .01\n",
    "\n",
    "input_img = Input(shape=(32, 32, 3), dtype='float32', name='main_input')\n",
    "\n",
    "## SHARED LAYERS\n",
    "net_shared = Conv2D(8, (4, 4), strides=(1, 1), padding='same', activation='elu')(input_img)\n",
    "net_shared = Conv2D(8, (4, 4), strides=(1, 1), padding='same', activation='elu')(net_shared)\n",
    "net_shared = MaxPooling2D((2, 2), padding='valid')(net_shared)\n",
    "net_shared = Conv2D(16, (4, 4), strides=(1, 1), padding='same', activation='elu')(net_shared)\n",
    "net_shared = Conv2D(16, (4, 4), strides=(1, 1), padding='same', activation='elu')(net_shared)\n",
    "net_shared = MaxPooling2D((2, 2), padding='valid')(net_shared)\n",
    "net_shared = Conv2D(32, (4, 4), strides=(1, 1), padding='same', activation='elu')(net_shared)\n",
    "\n",
    "# COARSE CLASSIFIER\n",
    "# Get the coarse predictions from fine\n",
    "output_c = indep_layers(net_shared, '0')\n",
    "\n",
    "base_model = Model(inputs=input_img, outputs=output_c)\n",
    "\n",
    "base_model.compile(optimizer= 'adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "45000/45000 [==============================] - 152s - loss: 4.3385 - acc: 0.0482 - val_loss: 3.8313 - val_acc: 0.1214\n",
      "Epoch 2/2\n",
      "45000/45000 [==============================] - 148s - loss: 3.7915 - acc: 0.1176 - val_loss: 3.5400 - val_acc: 0.1630\n"
     ]
    }
   ],
   "source": [
    "base_model.fit(x_train, y_train_adj, initial_epoch=0, epochs=300, batch_size=256, validation_split=.1)\n",
    "base_model.save_weights('data/models/base_model_'+str(500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define New Thresholding Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "\n",
    "from keras.layers import initializers, regularizers, constraints\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import backend as K\n",
    "from keras.legacy import interfaces\n",
    "\n",
    "class Threshold(Layer):\n",
    "    \"\"\"Thresholded Rectified Linear Unit.\n",
    "    It follows:\n",
    "    `f(x) = 1 for x > theta`,\n",
    "    `f(x) = 0 otherwise`.\n",
    "    # Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "    # Output shape\n",
    "        Same shape as the input.\n",
    "    # Arguments\n",
    "        theta: float >= 0. Threshold value.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, theta=.5, **kwargs):\n",
    "        super(Threshold, self).__init__(**kwargs)\n",
    "        self.theta = K.cast_to_floatx(theta)\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        return K.cast(K.greater(inputs, self.theta), K.floatx())\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'theta': float(self.theta)}\n",
    "        base_config = super(Threshold, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Threshold and Probabalistic Averaging Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_prob_ave(fine_pred, fine_to_coarse):\n",
    "    coarse_pred = Dot(1)([fine_pred,fine_to_coarse])\n",
    "    coarse_pred_adj = RepeatVector(100)(coarse_pred)\n",
    "    coarse_pred_adj = Flatten()(coarse_pred_adj)\n",
    "    prob_ave = Multiply()([fine_to_coarse, coarse_pred_adj])\n",
    "\n",
    "    return prob_ave\n",
    "\n",
    "def calc_threshold(fine_pred, fine_to_coarse, shared_layer):\n",
    "    coarse_pred = Dot(1)([fine_pred, fine_to_coarse])\n",
    "    coarse_pred_thresholded = Threshold()(coarse_pred)\n",
    "    threshold_adj = RepeatVector(32*8*8)(coarse_pred_thresholded)\n",
    "    threshold_adj = Reshape((8, 8, 32))(threshold_adj)\n",
    "    shared_layer_adj = Multiply()([shared_layer, threshold_adj])\n",
    "    \n",
    "    return shared_layer_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create an array of inputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fine_inputs = [Input(shape=([100]), dtype='float32', name='c0'), \\\n",
    "        Input(shape=([100]), dtype='float32', name='c1'), \\\n",
    "        Input(shape=([100]), dtype='float32', name='c2'), \\\n",
    "        Input(shape=([100]), dtype='float32', name='c3'), \\\n",
    "        Input(shape=([100]), dtype='float32', name='c4'), \\\n",
    "        Input(shape=([100]), dtype='float32', name='c5'), \\\n",
    "        Input(shape=([100]), dtype='float32', name='c6'), \\\n",
    "        Input(shape=([100]), dtype='float32', name='c7'), \\\n",
    "        Input(shape=([100]), dtype='float32', name='c8'), \\\n",
    "        Input(shape=([100]), dtype='float32', name='c9'), \\\n",
    "        Input(shape=([100]), dtype='float32', name='c10'), \\\n",
    "        Input(shape=([100]), dtype='float32', name='c11'), \\\n",
    "        Input(shape=([100]), dtype='float32', name='c12'), \\\n",
    "        Input(shape=([100]), dtype='float32', name='c13'), \\\n",
    "        Input(shape=([100]), dtype='float32', name='c14'), \\\n",
    "        Input(shape=([100]), dtype='float32', name='c15'), \\\n",
    "        Input(shape=([100]), dtype='float32', name='c16'), \\\n",
    "        Input(shape=([100]), dtype='float32', name='c17'), \\\n",
    "        Input(shape=([100]), dtype='float32', name='c18'), \\\n",
    "        Input(shape=([100]), dtype='float32', name='c19')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add Fine Layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    thresholded = calc_threshold(base_model.output, fine_inputs[i], net_shared)\n",
    "    fine_output = indep_layers(thresholded, str(i+1))\n",
    "\n",
    "    prob_ave = calc_prob_ave(output_c, fine_inputs[i])\n",
    "\n",
    "    weighted = Multiply()([fine_output, prob_ave])\n",
    "    \n",
    "    if i==0: output_f = weighted\n",
    "    else: output_f = Add()([weighted, output_f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile new network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = fine_inputs\n",
    "\n",
    "model = Model(inputs=[base_model.input, c[0], c[1], c[2], c[3], c[4], c[5], c[6], c[7], c[8], c[9], c[10], c[11], c[12], c[13], c[14], c[15], c[16], c[17], c[18], c[19]], \n",
    "              outputs=output_f)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer= 'adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Coarse Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer_name = layer.get_config()['name']\n",
    "    if 'shared_layer' in layer_name:\n",
    "        seg = layer_name.split('__')[1]\n",
    "        for f_layer in model.layers:\n",
    "            if seg in f_layer.get_config()['name']:\n",
    "                f_layer.set_weights(layer.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Coarse-To-Fine Mappings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get Coarse to Fine Mappings\n",
    "C2K = np.loadtxt('C2K.txt', dtype=int)\n",
    "C2K_dot = np.zeros((20,100))\n",
    "for i in range(len(C2K)):\n",
    "    C2K_dot[C2K[i], i] = 1\n",
    "\n",
    "#np.set_printoptions(threshold=np.inf)\n",
    "#print(C2K_dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "45000/45000 [==============================] - 767s - loss: 4.0365 - acc: 0.0670 - val_loss: 3.9694 - val_acc: 0.0740\n",
      "Epoch 2/2\n",
      "45000/45000 [==============================] - 690s - loss: 4.0867 - acc: 0.0692 - val_loss: 4.0096 - val_acc: 0.0750\n"
     ]
    }
   ],
   "source": [
    "ck = np.zeros((20, len(x_train), len(C2K_dot[0])))\n",
    "for i in range(len(x_train)):\n",
    "    for j in range(20):\n",
    "        ck[j,i] = C2K_dot[j]\n",
    "\n",
    "index= 0\n",
    "step = 25\n",
    "stop = 500\n",
    "\n",
    "while index < stop:\n",
    "    model.fit([x_train, ck[0], ck[1], ck[2], ck[3], ck[4], ck[5], ck[6], ck[7], ck[8], ck[9], ck[10], ck[11], ck[12], ck[13], ck[14], ck[15], ck[16], ck[17], ck[18], ck[19]],\\\n",
    "              y_train_adj, initial_epoch=index, epochs=index+step, batch_size=256, validation_split=.1)\n",
    "    model.save_weights('data/models/layer_'+str(index))\n",
    "    index += step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate on testing set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ct = np.zeros((20,len(x_test),100))\n",
    "for i in range(len(x_test)):\n",
    "    for j in range(20):\n",
    "        ct[j,i] = C2K_dot[j]\n",
    "        \n",
    "model.evaluate([x_test, ck[0], ck[1], ck[2], ck[3], ck[4], ck[5], ck[6], ck[7], ck[8], ck[9], ck[10], ck[11], ck[12], ck[13], ck[14], ck[15], ck[16], ck[17], ck[18], ck[19]],\\\n",
    "          y_test_adj, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
